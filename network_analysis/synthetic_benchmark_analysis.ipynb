{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_statistics(G, mode='cell_values_only'):\n",
    "    '''\n",
    "    Returns a pandas dataframe of relevant statistical measurements on the graph\n",
    "    Each row corresponds to one node in the graph\n",
    "    '''\n",
    "    print('Input graph has:', len(G.nodes()), 'nodes and', len(G.edges()), 'edges.')\n",
    "\n",
    "    density = nx.function.density(G)\n",
    "    print('Density:', density)\n",
    "\n",
    "    # Calculate various measures on a per-node level\n",
    "    if mode == 'cell_values_only':\n",
    "        print('Calculating local clustering coefficient...')\n",
    "        local_clustering_coefficient = nx.algorithms.cluster.clustering(G)\n",
    "        print('Calculating betweeness centrality...')\n",
    "        betweenness_centrality = nx.algorithms.centrality.betweenness_centrality(G)\n",
    "    elif mode == 'bipartite':\n",
    "        start = timer()\n",
    "        print('Calculating local clustering coefficient using dot mode...')\n",
    "        local_clustering_coefficient = nx.algorithms.bipartite.cluster.clustering(G)\n",
    "        print('Finished calculating local clustering coefficient using dot mode')\n",
    "        print('Elapsed time:', timer()-start, 'seconds\\n')\n",
    "\n",
    "        start = timer()\n",
    "        cell_nodes = {n for n, d in G.nodes(data=True) if d['type']=='cell'}\n",
    "        # TODO: betweeness takes a lot of time\n",
    "        print('Calculating betweeness centrality...')\n",
    "        betweenness_centrality = nx.algorithms.bipartite.centrality.betweenness_centrality(G, nodes=cell_nodes)\n",
    "        print('Finished calculating betweeness centrality')\n",
    "        print('Elapsed time:', timer()-start, 'seconds\\n')\n",
    "\n",
    "    # Construct the dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['node'] = local_clustering_coefficient.keys()\n",
    "    df['local_clustering_coefficient'] = local_clustering_coefficient.values()\n",
    "    df['betweenness_centrality'] = betweenness_centrality.values()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_homographs_and_identical_values(df_pairs):\n",
    "    '''\n",
    "    Given the pairs of instance cell nodes return a list of the global_cell values\n",
    "    that are identified as homographs and as identical values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    homographs_list: list of global cell values that are homographs\n",
    "\n",
    "    identical_list: list of global cell values that are identical words\n",
    "    '''\n",
    "    df_homograph_pairs = df_pairs.loc[df_pairs['same_column'] == False]\n",
    "    df_identical_pairs = df_pairs.loc[df_pairs['same_column'] == True]\n",
    "\n",
    "    # All global cell values in `df_homograph_pairs` are homographs\n",
    "    homographs_set = set(df_homograph_pairs['global_cell_val'].unique())\n",
    "\n",
    "    # Some cell values in df_identical_pairs can still be homographs (e.g. jaguar_animal_1, jaguar_animal_2) they \n",
    "    # are identical instances but there exists a jaguar instance with a car meaning\n",
    "    identical_set = set(df_identical_pairs['global_cell_val'].unique()) - homographs_set\n",
    "\n",
    "    print('There are:', len(homographs_set), 'homograph words')\n",
    "    print('There are:', len(identical_set), 'identical words')\n",
    "\n",
    "    return list(homographs_set), list(identical_set)\n",
    "\n",
    "def get_LCC_from_graph(G, graph_type='bipartite', mode='dot'):\n",
    "    '''\n",
    "    Return a dictionary of the LCC scores for each node in graph G\n",
    "\n",
    "    Arguments\n",
    "    -------\n",
    "        G (networkx graph): a networkx graph to be analyzed\n",
    "\n",
    "        graph_type (str): representation of the input graph\n",
    "        must be one of {bipartite, cell_graph} \n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    python dictionary keyed by node name mapping to its LCC score\n",
    "    '''\n",
    "    print('Input graph has:', G.number_of_nodes(), 'nodes and', G.number_of_edges(), 'edges.')\n",
    "\n",
    "    density = nx.function.density(G)\n",
    "    print('Density:', density, '\\n')\n",
    "\n",
    "    # Calculate various measures on a per-node level\n",
    "    if graph_type == 'cell_graph':\n",
    "        start = timer()\n",
    "        print('Calculating local clustering coefficient...')\n",
    "        local_clustering_coefficient = nx.algorithms.cluster.clustering(G)\n",
    "        print('Finished calculating local clustering coefficient \\n Elapsed time:', timer()-start, 'seconds\\n')\n",
    "    elif graph_type == 'bipartite':\n",
    "        # Find how many cell nodes only appear in one column (i.e. they have degree of 1)\n",
    "        cell_nodes = {n for n, d in G.nodes(data=True) if d['type']=='cell'}\n",
    "        degree_view = G.degree(cell_nodes)\n",
    "\n",
    "        num_nodes_with_degree_greater_than_one = 0\n",
    "        for node in cell_nodes:\n",
    "            if degree_view[node] > 1:\n",
    "                num_nodes_with_degree_greater_than_one += 1\n",
    "\n",
    "        print('There are', num_nodes_with_degree_greater_than_one, 'cell nodes with degree greater than one. That is',\\\n",
    "        str(num_nodes_with_degree_greater_than_one / len(cell_nodes) * 100) + '% of all cell nodes.')\n",
    "\n",
    "        if mode == 'dot':\n",
    "            start = timer()\n",
    "            print('Calculating local clustering coefficient using dot mode...')\n",
    "            local_clustering_coefficient = nx.algorithms.bipartite.cluster.clustering(G, mode='dot')\n",
    "            print('Finished calculating local clustering coefficient using dot mode')\n",
    "            print('Elapsed time:', timer()-start, 'seconds\\n')\n",
    "        elif mode == 'min':\n",
    "            start = timer()\n",
    "            print('Calculating local clustering coefficient using min mode...')\n",
    "            local_clustering_coefficient = nx.algorithms.bipartite.cluster.clustering(G, mode='min')\n",
    "            print('Finished calculating local clustering coefficient using min mode')\n",
    "            print('Elapsed time:', timer()-start, 'seconds\\n')\n",
    "        elif mode == 'max':\n",
    "            start = timer()\n",
    "            print('Calculating local clustering coefficient using max mode...')\n",
    "            local_clustering_coefficient = nx.algorithms.bipartite.cluster.clustering(G, mode='max')\n",
    "            print('Finished calculating local clustering coefficient using max mode')\n",
    "            print('Elapsed time:', timer()-start, 'seconds\\n')\n",
    "\n",
    "    return local_clustering_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Benchmark (Bipartite Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthetic_bipartite_graph = pickle.load(open('../graph_construction/combined_graphs_output/synthetic_benchmark_bipartite/bipartite/bipartite.graph', 'rb'))\n",
    "LCC_dict = get_LCC_from_graph(synthetic_bipartite_graph, graph_type='bipartite', mode='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load dataframe of graph statistics from file\n",
    "synthetic_bipartite_graph_stats_df = pickle.load(open('output/synthetic_example_bipartite/graph_stats_df.pickle', 'rb'))\n",
    "\n",
    "# Assign LCC scores to each value in the dataframe\n",
    "synthetic_bipartite_graph_stats_df['local_clustering_coefficient'] = np.nan\n",
    "for idx in synthetic_bipartite_graph_stats_df.index:\n",
    "    node = synthetic_bipartite_graph_stats_df.at[idx, 'node']\n",
    "    synthetic_bipartite_graph_stats_df.at[idx, 'local_clustering_coefficient'] = LCC_dict[node]\n",
    "\n",
    "# Remove all attribute nodes from the data frame. We only want to analyze nodes of type cell\n",
    "cell_nodes = {n for n, d in synthetic_bipartite_graph.nodes(data=True) if d['type']=='cell'}\n",
    "synthetic_bipartite_graph_stats_df = synthetic_bipartite_graph_stats_df.loc[synthetic_bipartite_graph_stats_df['node'].isin(cell_nodes)]\n",
    "synthetic_bipartite_graph_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include cell values with more than 1 degree. All other cell nodes cannot be homographs\n",
    "cell_nodes = synthetic_bipartite_graph_stats_df['node'].values\n",
    "nodes_with_degree_greater_than_1 = [n for n in cell_nodes if synthetic_bipartite_graph.degree[n] > 1]\n",
    "synthetic_bipartite_graph_stats_df = synthetic_bipartite_graph_stats_df.loc[synthetic_bipartite_graph_stats_df['node'].isin(nodes_with_degree_greater_than_1)]\n",
    "\n",
    "# Based on the ground truth label each node as homograph or unambiguous value\n",
    "groundtruth_synthetic = pickle.load(open('ground_truth/synthetic_example_groundtruth_dict.pickle', 'rb'))\n",
    "synthetic_bipartite_graph_stats_df['is_homograph'] = synthetic_bipartite_graph_stats_df['node'].map(groundtruth_synthetic)\n",
    "synthetic_bipartite_graph_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Create output directory for figures\n",
    "Path(\"figures/synthetic_dataset\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename node with long name for easy plotting\n",
    "synthetic_bipartite_graph_stats_df.at[3134, 'node'] = 'Coiled Anther'\n",
    "\n",
    "topk_graph = alt.Chart(synthetic_bipartite_graph_stats_df.nlargest(55, 'betweenness_centrality'), title='').mark_bar(size=20).encode(\n",
    "    x=alt.X('node:N', sort='-y', axis=alt.Axis(title='', labelAngle=-40, labelFontSize=30)),\n",
    "    y=alt.Y('betweenness_centrality:Q', axis=alt.Axis(title='Betweenness Centrality', labelFontSize=28, titleFontSize=30, tickCount=8)),\n",
    "    color=alt.Color('is_homograph:N', legend=alt.Legend(title='Value Type', titleLimit=0, labelLimit=500))\n",
    ").properties(width=2800, height=600)\n",
    "topk_graph = topk_graph.configure_axis(labelLimit=450)\n",
    "\n",
    "topk_graph = topk_graph.configure_legend(\n",
    "    labelFontSize=38,\n",
    "    symbolSize=700,\n",
    "    titleFontSize=35,\n",
    "    strokeColor='gray',\n",
    "    fillColor='#EEEEEE',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='top-right'\n",
    ")\n",
    "\n",
    "topk_graph.save('figures/synthetic_dataset/synthetic_bipartite_betweenness_topk_55_wide.svg')\n",
    "topk_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying root cause of low betweenness for homograph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of all the homograph values and their betweeness\n",
    "homographs_graph = alt.Chart(synthetic_bipartite_graph_stats_df[synthetic_bipartite_graph_stats_df['is_homograph'] == 'homograph'], title='').mark_bar(size=15).encode(\n",
    "    x=alt.X('node:N', sort='-y', axis=alt.Axis(title='', labelAngle=-40, labelFontSize=23)),\n",
    "    y=alt.Y('betweenness_centrality:Q', axis=alt.Axis(title='Betweenness Centrality', labelFontSize=26, titleFontSize=30, tickCount=8)),\n",
    "    color=alt.Color('is_homograph:N', legend=alt.Legend(title='Value Type', titleLimit=0, labelLimit=500))\n",
    ").properties(width=1600, height=800)\n",
    "homographs_graph = homographs_graph.configure_axis(labelLimit=550)\n",
    "\n",
    "homographs_graph = homographs_graph.configure_legend(\n",
    "    labelFontSize=38,\n",
    "    symbolSize=700,\n",
    "    titleFontSize=35,\n",
    "    strokeColor='gray',\n",
    "    fillColor='#EEEEEE',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='top-right'\n",
    ")\n",
    "\n",
    "homographs_graph.save('figures/synthetic_dataset/synthetic_bipartite_betweenness_homographs.svg')\n",
    "homographs_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_bipartite_graph_stats_df[synthetic_bipartite_graph_stats_df['is_homograph'] == 'homograph']['node'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All homographs with low betweeness in a dataframe\n",
    "homographs_with_low_betweeness = synthetic_bipartite_graph_stats_df[(synthetic_bipartite_graph_stats_df['is_homograph'] == 'homograph') &\n",
    "    (synthetic_bipartite_graph_stats_df['betweenness_centrality'] < \n",
    "        synthetic_bipartite_graph_stats_df[synthetic_bipartite_graph_stats_df['node'] == 'Florida']['betweenness_centrality'].values[0])]\n",
    "homographs_with_low_betweeness.sort_values(by=['betweenness_centrality'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Node Jaguar has neighbors:')\n",
    "for neighbor in synthetic_bipartite_graph.neighbors('Jaguar'):\n",
    "    print(neighbor, 'is connected to', len(list(synthetic_bipartite_graph.neighbors(neighbor))), 'nodes.')\n",
    "print('\\nNode AL has neighbors:')\n",
    "for neighbor in synthetic_bipartite_graph.neighbors('AL'):\n",
    "    print(neighbor, 'is connected to', len(list(synthetic_bipartite_graph.neighbors(neighbor))), 'nodes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that homographs with low betweeness is due to a small number of cell nodes neighboring their attribute nodes. For example the node 'AL' is a homograph because it is an abbreviation for the state of \"Alabama\" and the country \"Albania\". Because the total number of countries + us_states is small the betweeness centrality is much smaller. Moreover there is considerable intersection between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "homograph_df = synthetic_bipartite_graph_stats_df[synthetic_bipartite_graph_stats_df['is_homograph'] == 'homograph']\n",
    "num_of_second_degree_neighbors_list = []\n",
    "# Find the number of unique neighbors of neighbors for a each homograph node\n",
    "for node in homograph_df['node']:\n",
    "    unique_second_degree_neighbors = set()\n",
    "    for neighbor in list(synthetic_bipartite_graph.neighbors(node)):\n",
    "        unique_second_degree_neighbors |= set(synthetic_bipartite_graph.neighbors(neighbor))\n",
    "    num_of_second_degree_neighbors_list.append(len(unique_second_degree_neighbors))\n",
    "homograph_df['num_second_degree_neighbors'] = num_of_second_degree_neighbors_list\n",
    "homograph_df.sort_values(by=['num_second_degree_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = alt.Chart(homograph_df, title='').mark_circle(size=300, clip=True).encode(\n",
    "    x=alt.X('num_second_degree_neighbors:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Cardinality', labelFontSize=28, titleFontSize=30)),\n",
    "    y=alt.Y('betweenness_centrality:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Betweenness Centrality', format=\".1e\", labelFontSize=28, titleFontSize=30, tickCount=8)),\n",
    "    tooltip=['node', 'betweenness_centrality', 'num_second_degree_neighbors']\n",
    ")\n",
    "\n",
    "text = points.mark_text(\n",
    "    fontSize=32,\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    dy=-25\n",
    ").encode(\n",
    "    text='node'\n",
    ")\n",
    "\n",
    "fig = (text + points).properties(width=1600, height=800)\n",
    "fig.save('figures/synthetic_dataset/synthetic_bipartite_betweenness_vs_cardinality_all.svg')\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = alt.Chart(homograph_df, title='').mark_circle(size=300, clip=True).encode(\n",
    "    x=alt.X('num_second_degree_neighbors:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Cardinality', labelFontSize=28, titleFontSize=30)),\n",
    "    y=alt.Y('betweenness_centrality:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Betweenness Centrality', format=\".1e\", labelFontSize=28, titleFontSize=30, tickCount=8)),\n",
    "    tooltip=['node', 'betweenness_centrality', 'num_second_degree_neighbors']\n",
    ")\n",
    "\n",
    "\n",
    "fig = points.properties(width=1600, height=800)\n",
    "fig.save('figures/synthetic_dataset/synthetic_bipartite_betweenness_vs_cardinality_all_no_text.svg')\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_to_select = ['ME', 'MD', 'AL', 'Georgia', 'Ram', 'GT', 'California', 'ES', 'Florida', 'Cuba', 'Jamaica', 'Lincoln', 'Jaguar', 'Elan', 'Conroy', 'Virginia', 'Mace', 'Phoenix']\n",
    "homograph_df_filtered = homograph_df.loc[homograph_df['node'].isin(vals_to_select)]\n",
    "homograph_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = alt.Chart(homograph_df_filtered, title='').mark_circle(size=300, clip=True).encode(\n",
    "    x=alt.X('num_second_degree_neighbors:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Cardinality', labelFontSize=28, titleFontSize=30)),\n",
    "    y=alt.Y('betweenness_centrality:Q', scale=alt.Scale(type='log'), axis=alt.Axis(title='Betweenness Centrality', format=\".1e\", labelFontSize=28, titleFontSize=30, tickCount=8)),\n",
    "    tooltip=['node', 'betweenness_centrality', 'num_second_degree_neighbors']\n",
    ")\n",
    "\n",
    "text = points.mark_text(\n",
    "    fontSize=32,\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    dy=-25\n",
    ").encode(\n",
    "    text='node'\n",
    ")\n",
    "\n",
    "fig = (text + points).properties(width=1600, height=800)\n",
    "fig.save('figures/synthetic_dataset/synthetic_bipartite_betweenness_vs_cardinality.svg')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Clustering Coefficients Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-k graph for LCC measure\n",
    "topk_graph_LCC = alt.Chart(synthetic_bipartite_graph_stats_df.nsmallest(55, 'local_clustering_coefficient'), title='').mark_bar(size=20).encode(\n",
    "    x=alt.X('node:N', sort='y', axis=alt.Axis(title='', labelAngle=-40, labelFontSize=30)),\n",
    "    y=alt.Y('local_clustering_coefficient:Q', scale=alt.Scale(domain=(0, 0.55)), axis=alt.Axis(title='Local Clustering Coefficient', labelFontSize=30, titleFontSize=30, tickCount=8)),\n",
    "    color=alt.Color('is_homograph:N', legend=alt.Legend(title='Value Type', titleLimit=0, labelLimit=500))\n",
    ").properties(width=2800, height=600)\n",
    "topk_graph_LCC = topk_graph_LCC.configure_axis(labelLimit=550)\n",
    "\n",
    "topk_graph_LCC = topk_graph_LCC.configure_legend(\n",
    "    labelFontSize=38,\n",
    "    symbolSize=700,\n",
    "    titleFontSize=35,\n",
    "    strokeColor='gray',\n",
    "    fillColor='#EEEEEE',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='top-left'\n",
    ")\n",
    "\n",
    "topk_graph_LCC.save('figures/synthetic_dataset/synthetic_bipartite_LCC_topk_55_wide.svg')\n",
    "topk_graph_LCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of all the homograph values and their LCC scores\n",
    "homographs_graph_LCC = alt.Chart(synthetic_bipartite_graph_stats_df[synthetic_bipartite_graph_stats_df['is_homograph'] == 'homograph'], title='').mark_bar(size=24).encode(\n",
    "    x=alt.X('node:N', sort='y', axis=alt.Axis(title='', labelAngle=-40, labelFontSize=23)),\n",
    "    y=alt.Y('local_clustering_coefficient:Q', axis=alt.Axis(title='Local Clustering Coefficient', labelFontSize=26, titleFontSize=30, tickCount=8)),\n",
    "    color=alt.Color('is_homograph:N', legend=alt.Legend(title='Value Type', titleLimit=0, labelLimit=500))\n",
    ").properties(width=1600, height=800)\n",
    "homographs_graph_LCC = homographs_graph_LCC.configure_axis(labelLimit=550)\n",
    "\n",
    "homographs_graph_LCC = homographs_graph_LCC.configure_legend(\n",
    "    labelFontSize=38,\n",
    "    symbolSize=700,\n",
    "    titleFontSize=35,\n",
    "    strokeColor='gray',\n",
    "    fillColor='#EEEEEE',\n",
    "    padding=10,\n",
    "    cornerRadius=10,\n",
    "    orient='top-left'\n",
    ")\n",
    "\n",
    "homographs_graph_LCC.save('figures/synthetic_dataset/synthetic_bipartite_LCC_homographs.svg')\n",
    "homographs_graph_LCC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}