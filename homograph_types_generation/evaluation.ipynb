{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(25, 16)}, font_scale=2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../network_analysis/')\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_stats_with_gt(df, gt_homographs):\n",
    "    '''\n",
    "    Returns an updated `df` that contains the `is_homograph` column\n",
    "    '''\n",
    "        \n",
    "    is_homograph_list=[]\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        if row['node_type']=='attr':\n",
    "            is_homograph_list.append(np.nan)\n",
    "        else:\n",
    "            if row['node'] in gt_homographs:\n",
    "                is_homograph_list.append(True)\n",
    "            else:\n",
    "                is_homograph_list.append(False)\n",
    "    \n",
    "    df['is_homograph']=is_homograph_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis over Synthetic Benchmark Large 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22969/22969 [00:01<00:00, 16809.56it/s]\n",
      "100%|██████████| 32715/32715 [00:01<00:00, 16924.36it/s]\n",
      "100%|██████████| 23480/23480 [00:01<00:00, 16285.55it/s]\n",
      "100%|██████████| 22552/22552 [00:01<00:00, 15991.36it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir='../network_analysis/output/synthetic_example_large3/'\n",
    "graph_dir='../graph_construction/combined_graphs_output/synthetic_benchmark_large3/'\n",
    "with open('datasets/synthetic_benchmark_large3/selected_homographs.json') as f:\n",
    "    gt_homographs=json.load(f)\n",
    "\n",
    "num_homographs=100\n",
    "modes=['homographs_traditional', 'homographs_symbolic_code', 'homographs_symbolic_numeric', 'homographs_null_equivalent']\n",
    "\n",
    "eval_dfs={}\n",
    "\n",
    "for mode in modes:\n",
    "    graph_stats_df=pd.read_pickle(input_dir+mode+'_'+str(num_homographs)+'/graph_stats_df.pickle')\n",
    "    \n",
    "    # Get graph and consider only cell nodes with greater than 1 degree\n",
    "    graph_stats_df = graph_stats_df[graph_stats_df['node_type']=='cell'].sort_values(by='approximate_betweenness_centrality', ascending=False)\n",
    "    with open(graph_dir+mode+'_'+str(num_homographs)+'/bipartite/bipartite.graph', 'rb') as f:\n",
    "        G=pickle.load(f)\n",
    "    nodes_with_degree_greater_than_1 = [n for n in graph_stats_df['node'].values if G.degree[n] > 1]\n",
    "    graph_stats_df = graph_stats_df.loc[graph_stats_df['node'].isin(nodes_with_degree_greater_than_1)]\n",
    "\n",
    "    # Add ground truth in the dataframe and perform evaluation\n",
    "    cur_gt_homographs=set(gt_homographs[mode])\n",
    "    graph_stats_df = graph_stats_with_gt(df=graph_stats_df, gt_homographs=cur_gt_homographs)\n",
    "    graph_stats_df = utils.calculate_measures(df=graph_stats_df, num_true_homographs=num_homographs)\n",
    "    \n",
    "    eval_dfs[mode]=graph_stats_df\n",
    "\n",
    "with open('evaluation/synthetic_benchmark_large3/eval_dfs.pickle', 'wb') as f:\n",
    "    pickle.dump(eval_dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform evaluation over all types (add type information over each homograph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
